#---------------------------------------------------------------------------------------------------------------------#
#èŠ‚ç‚¹ä½œè€…ï¼šhua   ä»£ç åœ°å€ï¼šhttps://github.com/kungful/ComfyUI_hua_boy.git
#---------------------------------------------------------------------------------------------------------------------#
import sys
from .hua_icons import icons
import typing as tg
import json
import os
import random
import numpy as np  # ç”¨äºå¤„ç†å›¾åƒæ•°æ®
from PIL import Image, ImageOps, ImageSequence, ImageFile
from PIL.PngImagePlugin import PngInfo
import folder_paths  # å‡è®¾è¿™æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰æ¨¡å—ï¼Œç”¨äºå¤„ç†æ–‡ä»¶è·¯å¾„
from comfy.cli_args import args
import comfy.utils # Need this import for Hua_LoraLoader
import node_helpers # Need this import for GradioInputImage
import torch # Need this import for GradioInputImage
from datetime import datetime # Need this import for Hua_Output
import barcode
from barcode.writer import ImageWriter
# Removed duplicate Image import, kept ImageDraw and ImageFont
from PIL import ImageDraw, ImageFont
from comfy.cli_args import args


OUTPUT_DIR = folder_paths.get_output_directory()
FONT_PATH = os.path.join(os.path.dirname(__file__),  "fonts/SimHei.ttf")

def find_key_by_name(prompt, name):
    for key, value in prompt.items():
        if isinstance(value, dict) and value.get("_meta", {}).get("title") == name:
            return key
    return None

def check_seed_node(json_file):
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
    if not json_file or not os.path.exists(os.path.join(OUTPUT_DIR, json_file)):
        print(f"JSON æ–‡ä»¶æ— æ•ˆæˆ–ä¸å­˜åœ¨: {json_file}")
        return gr.update(visible=False) # å¦‚æœæ–‡ä»¶æ— æ•ˆï¼Œéšè—ç§å­èŠ‚ç‚¹æŒ‡ç¤ºå™¨

    json_path = os.path.join(OUTPUT_DIR, json_file)
    try:
        with open(json_path, "r", encoding="utf-8") as file_json:
            prompt = json.load(file_json)
        seed_key = find_key_by_name(prompt, "ğŸ§™hua_gradioéšæœºç§")
        if seed_key is None:
            return gr.update(visible=False)
        else:
            return gr.update(visible=True)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"è¯»å–æˆ–è§£æ JSON æ–‡ä»¶æ—¶å‡ºé”™ ({json_file}): {e}")
        return gr.update(visible=False) # å‡ºé”™æ—¶ä¹Ÿéšè—

current_dir = os.path.dirname(os.path.abspath(__file__))# è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•
print("å½“å‰huaæ’ä»¶æ–‡ä»¶çš„ç›®å½•ä¸ºï¼š", current_dir)
parent_dir = os.path.dirname(os.path.dirname(current_dir))# è·å–ä¸Šä¸¤çº§ç›®å½•
sys.path.append(parent_dir)# å°†ä¸Šä¸¤çº§ç›®å½•æ·»åŠ åˆ° sys.path
from comfy.cli_args import args
from .hua_icons import icons




class GradioTextBad:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "string": ("STRING", {"multiline": True, "dynamicPrompts": True, "tooltip": "The text to be encoded."}),

            }
        }
    RETURN_TYPES = ("STRING",)
    OUTPUT_TOOLTIPS = ("A conditioning containing the embedded text used to guide the diffusion model.",)
    FUNCTION = "encode"

    CATEGORY = icons.get("hua_boy_one")
    DESCRIPTION = "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images."

    def encode(self,string):
        return (string,)

class GradioInputImage:
    @classmethod
    def INPUT_TYPES(s):
        input_dir = folder_paths.get_input_directory()
        files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]
        return {"required":
                    {"image": (sorted(files), {"image_upload": True})},
                }

    OUTPUT_TOOLTIPS = ("è¿™æ˜¯ä¸€ä¸ªgradioè¾“å…¥å›¾ç‰‡çš„èŠ‚ç‚¹",)
    FUNCTION = "load_image"
    OUTPUT_NODE = True
    CATEGORY = icons.get("hua_boy_one")
    RETURN_TYPES = ("IMAGE", "MASK")



    def load_image(self, image):
        image_path = folder_paths.get_annotated_filepath(image)
        print("laodimageå‡½æ•°è¯»å–å›¾åƒè·¯å¾„ä¸ºï¼š", image_path)

        img = node_helpers.pillow(Image.open, image_path)

        output_images = [] #ç”¨äºå­˜å‚¨å¤„ç†åçš„å›¾åƒçš„åˆ—è¡¨ã€‚
        output_masks = [] #ç”¨äºå­˜å‚¨å¯¹åº”æ©ç çš„åˆ—è¡¨ã€‚
        w, h = None, None # ç”¨äºå­˜å‚¨å›¾åƒçš„å®½åº¦å’Œé«˜åº¦ï¼Œåˆå§‹å€¼ä¸º Noneã€‚

        excluded_formats = ['MPO']  #è¿™é‡Œåªæ’é™¤äº† 'MPO' æ ¼å¼

        for i in ImageSequence.Iterator(img):
            i = node_helpers.pillow(ImageOps.exif_transpose, i)#æ ¹æ® EXIF æ•°æ®çº æ­£å›¾åƒæ–¹å‘

            if i.mode == 'I': #å¦‚æœå›¾åƒæ¨¡å¼ä¸º 'I'ï¼ˆ32 ä½æœ‰ç¬¦å·æ•´æ•°åƒç´ ï¼‰ï¼Œåˆ™å°†åƒç´ å€¼ç¼©æ”¾åˆ° [0, 1] èŒƒå›´ã€‚
                i = i.point(lambda i: i * (1 / 255))
            image = i.convert("RGB")#å°†å›¾åƒè½¬æ¢ä¸º RGB æ¨¡å¼

            if len(output_images) == 0: #å¦‚æœæ˜¯ç¬¬ä¸€å¸§ï¼Œåˆ™è®¾ç½®å›¾åƒçš„å®½åº¦å’Œé«˜åº¦ã€‚
                w = image.size[0]
                h = image.size[1]

            if image.size[0] != w or image.size[1] != h: #å¦‚æœä¸ç­‰äºé‚£ä¹ˆè·³è¿‡ä¸åŒ¹é…åˆå§‹å®½åº¦å’Œé«˜åº¦çš„å¸§ã€‚
                continue

            image = np.array(image).astype(np.float32) / 255.0 #å°†å›¾åƒè½¬æ¢ä¸º NumPy æ•°ç»„ï¼Œå¹¶å°†åƒç´ å€¼å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´ã€‚
            image = torch.from_numpy(image)[None,] #å°† NumPy æ•°ç»„è½¬æ¢ä¸º PyTorch å¼ é‡ã€‚
            if 'A' in i.getbands(): #æ£€æŸ¥å›¾åƒæ˜¯å¦æœ‰ alpha é€šé“ã€‚
                mask = np.array(i.getchannel('A')).astype(np.float32) / 255.0 #æå– alpha é€šé“å¹¶å°†å…¶å½’ä¸€åŒ–ã€‚
                mask = 1. - torch.from_numpy(mask)#åè½¬æ©ç ï¼ˆå‡è®¾ alpha é€šé“è¡¨ç¤ºé€æ˜åº¦ï¼‰
            else:
                mask = torch.zeros((64,64), dtype=torch.float32, device="cpu") #å¦‚æœæ²¡æœ‰ alpha é€šé“ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªå¤§å°ä¸º (64, 64) çš„é›¶æ©ç ã€‚
            output_images.append(image) #å°†å¤„ç†åçš„å›¾åƒæ·»åŠ åˆ°åˆ—è¡¨ä¸­ã€‚
            output_masks.append(mask.unsqueeze(0)) #å°†æ©ç æ·»åŠ åˆ°åˆ—è¡¨ä¸­ã€‚

        if len(output_images) > 1 and img.format not in excluded_formats:#æ£€æŸ¥å¤„ç†åçš„å›¾åƒå¸§æ•°é‡æ˜¯å¦å¤§äº 1ã€‚å¦‚æœå¤§äº 1ï¼Œè¯´æ˜å›¾åƒåŒ…å«å¤šä¸ªå¸§ï¼ˆä¾‹å¦‚ GIF æˆ–å¤šå¸§å›¾åƒï¼‰ã€‚ æ£€æŸ¥å›¾åƒæ ¼å¼æ˜¯å¦ä¸åœ¨æ’é™¤çš„æ ¼å¼åˆ—è¡¨ä¸­ã€‚
            output_image = torch.cat(output_images, dim=0)# å°†æ‰€æœ‰å¤„ç†åçš„å›¾åƒæ²¿æ‰¹æ¬¡ç»´åº¦ï¼ˆdim=0ï¼‰è¿æ¥èµ·æ¥ã€‚å‡è®¾ output_images æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªå›¾åƒå¼ é‡çš„åˆ—è¡¨ï¼Œtorch.cat ä¼šå°†è¿™äº›å¼ é‡åœ¨æ‰¹æ¬¡ç»´åº¦ä¸Šæ‹¼æ¥æˆä¸€ä¸ªå¤§çš„å¼ é‡ã€‚
            output_mask = torch.cat(output_masks, dim=0)#å°†æ‰€æœ‰æ©ç æ²¿æ‰¹æ¬¡ç»´åº¦ï¼ˆdim=0ï¼‰è¿æ¥èµ·æ¥ã€‚å‡è®¾ output_masks æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªæ©ç å¼ é‡çš„åˆ—è¡¨ï¼Œtorch.cat ä¼šå°†è¿™äº›å¼ é‡åœ¨æ‰¹æ¬¡ç»´åº¦ä¸Šæ‹¼æ¥æˆä¸€ä¸ªå¤§çš„å¼ é‡ã€‚
        else:
            # å•å¸§æƒ…å†µï¼š
            output_image = output_images[0] #å¦‚æœå›¾åƒåªæœ‰ä¸€ä¸ªå¸§æˆ–æ ¼å¼åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ç¬¬ä¸€ä¸ªå¸§ä½œä¸ºè¾“å‡ºå›¾åƒã€‚
            output_mask = output_masks[0]#åŒæ ·ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¸§çš„æ©ç ä½œä¸ºè¾“å‡ºæ©ç ã€‚

        return (output_image, output_mask) #è¿”å›ä¸€ä¸ªåŒ…å«å¤„ç†åçš„å›¾åƒåŠå…¶å¯¹åº”æ©ç çš„å…ƒç»„ã€‚






#_________________________________________________æ¡å½¢ç ç”Ÿæˆå™¨____________________________________________________#
class Barcode_seed:

    @classmethod
    def INPUT_TYPES(cls):
        return {"required": {
            "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff})}}

    RETURN_TYPES = ("INT", "STRING", )
    RETURN_NAMES = ("ç§å­å€¼", "å¸®åŠ©é“¾æ¥", )
    FUNCTION = "hua_seed"
    OUTPUT_NODE = True
    CATEGORY = icons.get("hua_boy_one")

    @staticmethod
    def hua_seed(seed):
        show_help = "https://github.com/kungful/ComfyUI_hua_boy.git"
        return (seed, show_help,)

class BarcodeGeneratorNode: # ç±»åä¿®æ”¹å¾—æ›´æ¸…æ™°
    # ç”¨äºå­˜å‚¨ä¸Šä¸€æ¬¡è¿è¡Œçš„æ•°å­— - æ³¨æ„ï¼šComfyUI èŠ‚ç‚¹é€šå¸¸æ˜¯æ— çŠ¶æ€çš„ï¼Œ
    # æ¯æ¬¡æ‰§è¡Œéƒ½æ˜¯ç‹¬ç«‹çš„ã€‚è¿™ç§ç±»çº§åˆ«çš„å˜é‡å¯èƒ½ä¸ä¼šæŒ‰é¢„æœŸè·¨æ‰§è¡Œä¿ç•™çŠ¶æ€ã€‚
    # å®ç°è‡ªåŠ¨é€’å¢çš„æ›´å¯é æ–¹æ³•æ˜¯åœ¨å·¥ä½œæµä¸­å°†è¾“å‡ºè¿æ¥å›è¾“å…¥ï¼Œ
    # æˆ–è€…è®©ç”¨æˆ·æ‰‹åŠ¨æ›´æ–°è¾“å…¥ã€‚
    # è¿™é‡Œæˆ‘ä»¬å®ç°ä¸€ä¸ªç®€å•çš„é€»è¾‘ï¼šæ¥æ”¶è¾“å…¥æ•°å­—ï¼Œå°†å…¶+1åç”¨äºç”Ÿæˆã€‚
    # last_number = None # æš‚æ—¶ä¸ä½¿ç”¨ç±»å˜é‡å­˜å‚¨çŠ¶æ€

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "å‰ç¼€": ("STRING", { # ä¿®æ”¹é”®å
                    "display_name": "å‰ç¼€(å¯é€‰)",
                    "multiline": False,
                    "default": "" # é»˜è®¤å‰ç¼€ä¸ºç©º
                }),
                "è¾“å…¥æ•°å­—": ("INT", { # ä¿®æ”¹ä¸ºINTç±»å‹
                    "display_name": "èµ·å§‹æ•°å­—",
                    "default": 0, # é»˜è®¤ä»0å¼€å§‹
                    "min": 0,
                    "max": 0xffffffffffffffff
                }),
                 "å­—ä½“å¤§å°": ("INT", { # ä¿®æ”¹é”®å
                    "display_name": "æ–‡æœ¬å¤§å°(px)",
                    "default": 25,
                    "min": 10,
                    "max": 200,
                    "step": 1
                }),
                    "æ¡ç é«˜åº¦ç¼©æ”¾": ("FLOAT", { # ä¿®æ”¹é”®å
                        "display_name": "æ¡ç é«˜åº¦æ¯”ä¾‹",
                        "default": 0.5,
                        "min": 0.1, # å°†æœ€å°å€¼æ”¹ä¸º 0.1
                        "max": 3.0,
                        "step": 0.1
                    }),
                 "æ–‡æœ¬ä¸‹è¾¹è·": ("INT", { # ä¿®æ”¹é”®å
                    "display_name": "æ–‡æœ¬åº•éƒ¨é—´è·(px)",
                    "default": 15,
                    "min": 5,
                    "max": 50,
                    "step": 1
                }),
                "æ¡ç ä¸æ–‡æœ¬é—´è·": ("INT", { # æ–°å¢å‚æ•°
                    "display_name": "æ¡ç ä¸æ–‡æœ¬é—´è·(px)",
                    "default": 10,
                    "min": -80, # å…è®¸è´Ÿå€¼ä»¥å‡å°‘é—´è·
                    "max": 50,
                    "step": 1
                }),
                "å·¦å³è¾¹è·": ("FLOAT", {
                    "display_name": "å·¦å³è¾¹è·æ¯”ä¾‹",
                    "default": 2.0,
                    "min": 0.0,
                    "max": 20.0,
                    "step": 0.5
                }),
                "é¡¶éƒ¨è¾¹è·": ("INT", {
                    "display_name": "é¡¶éƒ¨è¾¹è·(px)",
                    "default": 5,
                    "min": 0,
                    "max": 100,
                    "step": 1
                }),
                "å…¨å±€ç¼©æ”¾æ¯”ä¾‹": ("FLOAT", { # æ–°å¢å…¨å±€ç¼©æ”¾å‚æ•°
                    "display_name": "å…¨å±€ç¼©æ”¾æ¯”ä¾‹",
                    "default": 1.0,
                    "min": 0.1, # æœ€å°ç¼©æ”¾åˆ° 10%
                    "max": 10.0, # æœ€å¤§æ”¾å¤§åˆ° 10 å€
                    "step": 0.1
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK", "STRING") # å¢åŠ è¿”å›é€’å¢åçš„æ•°å­—å­—ç¬¦ä¸²
    RETURN_NAMES = ("æ¡å½¢ç å›¾åƒ", "å°ºå¯¸é®ç½©", "è¾“å‡ºæ•°å­—") # å·²æ±‰åŒ–
    FUNCTION = "generate"
    CATEGORY = icons.get("hua_boy_one") # ç»Ÿä¸€åˆ†ç±»å‰ç¼€

    # --- Helper for PIL version compatibility ---
    try:
        RESAMPLING_MODE = Image.Resampling.LANCZOS
    except AttributeError:
        # Fallback for older PIL versions
        RESAMPLING_MODE = Image.LANCZOS
    # --- End Helper ---

    def validate_number_input(self, num):
        """éªŒè¯è¾“å…¥æ•°å­—èŒƒå›´"""
        if num < 0:
            raise ValueError("é”™è¯¯ï¼šèµ·å§‹æ•°å­—ä¸èƒ½ä¸ºè´Ÿæ•°")
        return num

    def draw_text(self, img, text, font_path, font_size, top_y): # ä¿®æ”¹å‚æ•°å bottom_margin -> top_y
        """åœ¨å›¾åƒæŒ‡å®š top_y ä½ç½®ç»˜åˆ¶æ–‡æœ¬ï¼Œæ”¯æŒä¸­è‹±æ–‡å­—ä½“ï¼Œå¹¶å±…ä¸­"""
        draw = ImageDraw.Draw(img)
        try:
            font = ImageFont.truetype(font_path, font_size)
        except IOError:
            print(f"è­¦å‘Šï¼šæ— æ³•åŠ è½½å­—ä½“ {font_path}ã€‚å°è¯•ä½¿ç”¨é»˜è®¤å­—ä½“ã€‚")
            try:
                # å°è¯•åŠ è½½ PIL é»˜è®¤å­—ä½“ï¼Œå¦‚æœå¯ç”¨
                font = ImageFont.load_default()
                # å¯¹äºé»˜è®¤å­—ä½“ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å¤§å°æˆ–æ¥å—å…¶å›ºæœ‰å¤§å°
                # font_size = 10 # å¯ä»¥å–æ¶ˆæ³¨é‡Šä»¥å¼ºåˆ¶é»˜è®¤å­—ä½“å¤§å°
            except IOError:
                print("è­¦å‘Šï¼šæ— æ³•åŠ è½½é»˜è®¤å­—ä½“ã€‚å°†ä¸ç»˜åˆ¶æ–‡æœ¬ã€‚")
                return img # æ— æ³•ç»˜åˆ¶æ–‡æœ¬ï¼Œè¿”å›åŸå›¾

        # ä½¿ç”¨ textbbox è·å–æ›´å‡†ç¡®çš„æ–‡æœ¬è¾¹ç•Œæ¡†
        try:
            # textbbox éœ€è¦ 4 ä¸ªå‚æ•° (xy, text, font, spacing) æˆ– (xy, text, font)
            # æˆ‘ä»¬å…ˆåœ¨ (0,0) å¤„è®¡ç®—å°ºå¯¸
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
        except AttributeError: # å…¼å®¹æ—§ç‰ˆ PIL å¯èƒ½æ²¡æœ‰ textbbox
             text_width, text_height = draw.textsize(text, font=font)


        # è®¡ç®—æ–‡æœ¬ç»˜åˆ¶ä½ç½®
        img_width, _ = img.size # åªéœ€å®½åº¦ç”¨äºå±…ä¸­
        x = (img_width - text_width) // 2
        # y åæ ‡ç°åœ¨ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ top_y
        y = top_y

        # ç»˜åˆ¶æ–‡æœ¬ (ä¸å†éœ€è¦æ£€æŸ¥ y æ˜¯å¦ä¸ºè´Ÿï¼Œå› ä¸ºå®ƒæ˜¯ä»é¡¶éƒ¨è®¡ç®—çš„)
        draw.text((x, y), text, font=font, fill="black")

        return img

    def generate(self, å‰ç¼€, è¾“å…¥æ•°å­—, å­—ä½“å¤§å°, æ¡ç é«˜åº¦ç¼©æ”¾, æ–‡æœ¬ä¸‹è¾¹è·, æ¡ç ä¸æ–‡æœ¬é—´è·, å·¦å³è¾¹è·, é¡¶éƒ¨è¾¹è·, å…¨å±€ç¼©æ”¾æ¯”ä¾‹): # æ·»åŠ å…¨å±€ç¼©æ”¾æ¯”ä¾‹å‚æ•°
        # 1. è¾“å…¥éªŒè¯
        try:
            # éªŒè¯æ•°å­—è¾“å…¥
            current_number = self.validate_number_input(è¾“å…¥æ•°å­—)
            # éªŒè¯ç¼©æ”¾æ¯”ä¾‹
            if å…¨å±€ç¼©æ”¾æ¯”ä¾‹ <= 0:
                raise ValueError("å…¨å±€ç¼©æ”¾æ¯”ä¾‹å¿…é¡»å¤§äº 0")
            next_number_str = str(è¾“å…¥æ•°å­—)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        except ValueError as e:
            print(f"è¾“å…¥é”™è¯¯: {e}")
            # å¯ä»¥è¿”å›ä¸€ä¸ªé”™è¯¯å›¾åƒæˆ–é»˜è®¤å›¾åƒ
            error_img = Image.new("RGB", (300, 100), "white")
            draw = ImageDraw.Draw(error_img)
            draw.text((10, 10), f"é”™è¯¯: {e}", fill="red")
            image_np = np.array(error_img).astype(np.float32) / 255.0
            image_tensor = torch.from_numpy(image_np)[None,]
            mask = torch.ones((100, 300), dtype=torch.float32)
            return (image_tensor, mask, str(è¾“å…¥æ•°å­—)) # è¿”å›åŸå§‹è¾“å…¥æ•°å­—

        # 2. ç”Ÿæˆæ¡å½¢ç æ ¸å¿ƒ (åªä½¿ç”¨é€’å¢åçš„æ•°å­—)
        try:
            code128 = barcode.get_barcode_class('code128')
            # è®¾ç½® writer é€‰é¡¹æ¥è°ƒæ•´æ¡ç æœ¬èº«å‚æ•°
            writer_options = {
                'module_height': 15.0 * æ¡ç é«˜åº¦ç¼©æ”¾, # æ§åˆ¶æ¡ç é«˜åº¦ï¼Œä½¿ç”¨ä¿®æ”¹åçš„å‚æ•°å
                'write_text': False, # ç¦ç”¨åº“è‡ªå¸¦çš„æ–‡æœ¬
                'quiet_zone': å·¦å³è¾¹è·, # ä½¿ç”¨è¾“å…¥å‚æ•°æ§åˆ¶å·¦å³è¾¹è·
                'dpi': int(300 * å…¨å±€ç¼©æ”¾æ¯”ä¾‹) # åŠ¨æ€è®¡ç®—dpiï¼Œæ ¹æ®ç¼©æ”¾æ¯”ä¾‹æé«˜åˆ†è¾¨ç‡
            }
            barcode_pil_img = code128(next_number_str, writer=ImageWriter()).render(writer_options)
        except Exception as e:
            print(f"æ¡å½¢ç ç”Ÿæˆé”™è¯¯: {e}")
            # è¿”å›é”™è¯¯å›¾åƒ
            error_img = Image.new("RGB", (300, 100), "white")
            draw = ImageDraw.Draw(error_img)
            draw.text((10, 10), f"æ¡ç é”™è¯¯: {e}", fill="red")
            image_np = np.array(error_img).astype(np.float32) / 255.0
            image_tensor = torch.from_numpy(image_np)[None,]
            mask = torch.ones((100, 300), dtype=torch.float32)
            return (image_tensor, mask, str(è¾“å…¥æ•°å­—)) # è¿”å›åŸå§‹è¾“å…¥æ•°å­—

        # 3. è®¡ç®—æœ€ç»ˆç”»å¸ƒå°ºå¯¸
        barcode_width, barcode_height = barcode_pil_img.size
        # ä¼°ç®—æ–‡æœ¬é«˜åº¦ï¼Œéœ€è¦åŠ è½½å­—ä½“
        try:
            font = ImageFont.truetype(FONT_PATH, å­—ä½“å¤§å°) # ä½¿ç”¨ä¿®æ”¹åçš„å‚æ•°å
            # ä¼°ç®—ç»„åˆæ–‡æœ¬çš„é«˜åº¦ (åªéœ€è¦æ–‡æœ¬æœ¬èº«çš„é«˜åº¦)
            combined_text = f"{å‰ç¼€}{next_number_str}" # ä½¿ç”¨ä¿®æ”¹åçš„å‚æ•°å
            bbox = ImageDraw.Draw(Image.new("RGB",(1,1))).textbbox((0,0), combined_text, font=font)
            text_actual_height = bbox[3] - bbox[1]
        except Exception:
            text_actual_height = å­—ä½“å¤§å° # ç²—ç•¥ä¼°è®¡

        # è®¡ç®—æ–‡æœ¬åŒºåŸŸæ€»å…±éœ€è¦çš„é«˜åº¦ = é—´è· + æ–‡æœ¬é«˜åº¦ + åº•éƒ¨è¾¹è·
        text_area_total_height = æ¡ç ä¸æ–‡æœ¬é—´è· + text_actual_height + æ–‡æœ¬ä¸‹è¾¹è·

        # ç¡®ä¿æœ€å°å°ºå¯¸
        min_width = 200
        min_height = 50 # é™ä½æœ€å°é«˜åº¦è¦æ±‚

        canvas_width = max(barcode_width, min_width)
        # æ€»é«˜åº¦ = é¡¶éƒ¨è¾¹è· + æ¡ç é«˜åº¦ + æ–‡æœ¬åŒºåŸŸæ€»é«˜åº¦
        # top_padding = 5 # ä¸å†ç¡¬ç¼–ç é¡¶éƒ¨ç•™ç™½
        canvas_height = max(é¡¶éƒ¨è¾¹è· + barcode_height + text_area_total_height, min_height) # ä½¿ç”¨è¾“å…¥å‚æ•°

        # 4. åˆ›å»ºç”»å¸ƒå¹¶å°†æ¡å½¢ç ç²˜è´´åˆ°é¡¶éƒ¨ï¼ˆå±…ä¸­ï¼‰
        canvas = Image.new("RGB", (canvas_width, canvas_height), "white")
        paste_x = (canvas_width - barcode_width) // 2
        paste_y = é¡¶éƒ¨è¾¹è· # ä½¿ç”¨è¾“å…¥å‚æ•°ä½œä¸ºé¡¶éƒ¨ç•™ç™½
        canvas.paste(barcode_pil_img, (paste_x, paste_y))

        # 5. åœ¨æ¡å½¢ç ä¸‹æ–¹ç»˜åˆ¶ç»„åˆæ–‡æœ¬
        combined_text_to_draw = f"{å‰ç¼€}{è¾“å…¥æ•°å­—}" # ä½¿ç”¨åŸå§‹è¾“å…¥æ•°å­—
        # è®¡ç®—æ–‡æœ¬ç»˜åˆ¶çš„é¡¶éƒ¨ Y åæ ‡
        text_top_y = paste_y + barcode_height + æ¡ç ä¸æ–‡æœ¬é—´è· # æ¡ç åº•éƒ¨ + é—´è·

        try:
            # è°ƒç”¨ä¿®æ”¹åçš„ draw_textï¼Œä¼ å…¥è®¡ç®—å¥½çš„ text_top_y
            canvas_with_text = self.draw_text(canvas, combined_text_to_draw, FONT_PATH, å­—ä½“å¤§å°, text_top_y)

        except Exception as e:
            print(f"ç»˜åˆ¶æ–‡æœ¬æ—¶å‡ºé”™: {e}")
            # å‡ºé”™ä¹Ÿç»§ç»­ï¼Œå¯èƒ½åªæ˜¾ç¤ºæ¡å½¢ç 
            canvas_with_text = canvas # ä½¿ç”¨æ²¡æœ‰æ–‡æœ¬çš„ç”»å¸ƒ

        # 6. åº”ç”¨å…¨å±€ç¼©æ”¾
        original_width, original_height = canvas_with_text.size
        scaled_width = max(1, int(original_width * å…¨å±€ç¼©æ”¾æ¯”ä¾‹)) # ç¡®ä¿æœ€å°ä¸º 1
        scaled_height = max(1, int(original_height * å…¨å±€ç¼©æ”¾æ¯”ä¾‹)) # ç¡®ä¿æœ€å°ä¸º 1

        if å…¨å±€ç¼©æ”¾æ¯”ä¾‹ != 1.0:
            try:
                print(f"åŸå§‹å°ºå¯¸: {original_width}x{original_height}, ç¼©æ”¾æ¯”ä¾‹: {å…¨å±€ç¼©æ”¾æ¯”ä¾‹}, ç¼©æ”¾åå°ºå¯¸: {scaled_width}x{scaled_height}")
                # åˆ›å»ºä¸´æ—¶é«˜åˆ†è¾¨ç‡ç”»å¸ƒè¿›è¡Œé«˜è´¨é‡ç¼©æ”¾
                temp_canvas = Image.new("RGB", (original_width, original_height), "white")
                temp_canvas.paste(canvas_with_text, (0, 0))
                # ä½¿ç”¨é«˜è´¨é‡çš„ LANCZOS æ»¤æ³¢å™¨è¿›è¡Œç¼©æ”¾ï¼Œå¹¶ä¿æŒé«˜åˆ†è¾¨ç‡
                final_canvas = temp_canvas.resize((scaled_width, scaled_height), self.RESAMPLING_MODE)
            except Exception as e:
                print(f"å›¾åƒç¼©æ”¾æ—¶å‡ºé”™: {e}")
                final_canvas = canvas_with_text # ç¼©æ”¾å¤±è´¥åˆ™è¿”å›åŸå§‹å›¾åƒ
        else:
            final_canvas = canvas_with_text # æ— éœ€ç¼©æ”¾

        # 7. è½¬æ¢ä¸º ComfyUI å…¼å®¹æ ¼å¼
        final_image_np = np.array(final_canvas).astype(np.float32) / 255.0
        final_image_tensor = torch.from_numpy(final_image_np)[None,]

        # åˆ›å»ºä¸æœ€ç»ˆç¼©æ”¾åå›¾åƒå°ºå¯¸åŒ¹é…çš„ mask
        final_height, final_width = final_image_np.shape[:2] # ä»ç¼©æ”¾åçš„ numpy æ•°ç»„è·å–å°ºå¯¸
        mask = torch.ones((final_height, final_width), dtype=torch.float32)

        # è¿”å›å›¾åƒã€mask å’ŒåŸå§‹è¾“å…¥æ•°å­—å­—ç¬¦ä¸²
        return (final_image_tensor, mask, str(è¾“å…¥æ•°å­—))

class Hua_gradio_Seed:

    @classmethod
    def INPUT_TYPES(cls):
        return {"required": {
            "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff})}}

    RETURN_TYPES = ("INT", "STRING", )
    RETURN_NAMES = ("seed", "show_help", )
    FUNCTION = "hua_seed"
    OUTPUT_NODE = True
    CATEGORY = icons.get("hua_boy_one")

    @staticmethod
    def hua_seed(seed):
        show_help = "https://github.com/kungful/ComfyUI_hua_boy.git"
        return (seed, show_help,)
#---------------------------------------------------------------------------------------------------------------------#




class GradioTextOk2:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "string": ("STRING", {"multiline": True, "dynamicPrompts": True, "tooltip": "The text to be encoded."}),

            }
        }
    RETURN_TYPES = ("STRING",)
    OUTPUT_TOOLTIPS = ("A conditioning containing the embedded text used to guide the diffusion model.",)
    FUNCTION = "encode"

    CATEGORY = icons.get("hua_boy_one")
    DESCRIPTION = "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images."

    def encode(self,string):
        return (string,)

class GradioTextOk3:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "string": ("STRING", {"multiline": True, "dynamicPrompts": True, "tooltip": "The text to be encoded."}),

            }
        }
    RETURN_TYPES = ("STRING",)
    OUTPUT_TOOLTIPS = ("A conditioning containing the embedded text used to guide the diffusion model.",)
    FUNCTION = "encode"

    CATEGORY = icons.get("hua_boy_one")
    DESCRIPTION = "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images."

    def encode(self,string):
        return (string,)

class GradioTextOk4:

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "string": ("STRING", {"multiline": True, "dynamicPrompts": True, "tooltip": "The text to be encoded."}),

            }
        }
    RETURN_TYPES = ("STRING",)
    OUTPUT_TOOLTIPS = ("A conditioning containing the embedded text used to guide the diffusion model.",)
    FUNCTION = "encode"

    CATEGORY = icons.get("hua_boy_one")
    DESCRIPTION = "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images."

    def encode(self,string):
        return (string,)

#---------------------------------------------------------------------------------------------------------------------#
class Hua_gradio_Seed:

    @classmethod
    def INPUT_TYPES(cls):
        return {"required": {
            "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff})}}

    RETURN_TYPES = ("INT", "STRING", )
    RETURN_NAMES = ("seed", "show_help", )
    FUNCTION = "hua_seed"
    OUTPUT_NODE = True
    CATEGORY = icons.get("hua_boy_one")

    @staticmethod
    def hua_seed(seed):
        show_help = "https://github.com/kungful/ComfyUI_hua_boy.git"
        return (seed, show_help,)
#---------------------------------------------------------------------------------------------------------------------#
class Hua_gradio_resolution:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "custom_width": ("INT", {"default": 512, "min": 64, "max": 8192, "step": 64}),
                "custom_height": ("INT", {"default": 512, "min": 64, "max": 8192, "step": 64}),
            }
        }

    RETURN_TYPES = ("INT", "INT",)
    RETURN_NAMES = ("width", "height",)
    FUNCTION = "get_resolutions"

    CATEGORY = icons.get("hua_boy_one")

    def get_resolutions(self, custom_width, custom_height):
        width, height = custom_width, custom_height


        return (width, height)
#---------------------------------------------------------------------------------------------------------------------#

class Hua_gradio_jsonsave:
    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()
        self.type = "output"
        self.prefix_append = ""
        self.compress_level = 4

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE", {"tooltip": "The images to save."}),
                "filename_prefix": ("STRING", {"default": "apijson", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."})
            },
            "hidden": {
                "prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"
            },
        }


    RETURN_TYPES = ()
    RETURN_NAMES = ()
    FUNCTION = "autosavejson"
    OUTPUT_NODE = True
    CATEGORY = icons.get("hua_boy_one")
    DESCRIPTION = "ä¿å­˜apiæ ¼å¼jsonå·¥ä½œæµåˆ°inputæ–‡ä»¶å¤¹ä¸‹"

    def autosavejson(self, images, filename_prefix="apijson", prompt=None, extra_pnginfo=None):
        filename_prefix += self.prefix_append
        full_output_folder, filename, counter, subfolder, filename_prefix = folder_paths.get_save_image_path(filename_prefix, self.output_dir, images[0].shape[1], images[0].shape[0])
        results = list()
        # results = []
        counter = 0  # åˆå§‹åŒ–è®¡æ•°å™¨
        for i, image in enumerate(images):
            imagefilename = f"{filename_prefix}_{i}.png"
            results.append({
                "imagefilename": imagefilename,
            })

            # Save JSON file
            filename_with_batch_num = f"{filename_prefix}"

            json_filename = f"{filename_with_batch_num}.json"
            json_data = prompt
            json_file_path = os.path.join(full_output_folder, json_filename)
            with open(json_file_path, 'w', encoding='utf-8') as json_file:
                json.dump(json_data, json_file, ensure_ascii=False, indent=4)

            # è°ƒè¯•ä¿¡æ¯0+
            print(f"ä¿å­˜çš„apiæ ¼å¼jsonæ–‡ä»¶ä½ç½®: {json_file_path}")
            counter += 1



        return { "ui": { "images": results } }


class Hua_LoraLoader:
    def __init__(self):
        self.loaded_lora = None

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "model": ("MODEL", {"tooltip": "The diffusion model the LoRA will be applied to."}),
                "clip": ("CLIP", {"tooltip": "The CLIP model the LoRA will be applied to."}),
                "lora_name": (folder_paths.get_filename_list("loras"), {"tooltip": "The name of the LoRA."}),
                "strength_model": ("FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the diffusion model. This value can be negative."}),
                "strength_clip": ("FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the CLIP model. This value can be negative."}),
            }
        }

    RETURN_TYPES = ("MODEL", "CLIP")
    OUTPUT_TOOLTIPS = ("The modified diffusion model.", "The modified CLIP model.")
    FUNCTION = "load_lora"

    CATEGORY = icons.get("hua_boy_one")
    DESCRIPTION = "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together."

    def load_lora(self, model, clip, lora_name, strength_model, strength_clip):
        if strength_model == 0 and strength_clip == 0:
            return (model, clip)

        lora_path = folder_paths.get_full_path_or_raise("loras", lora_name)
        lora = None
        if self.loaded_lora is not None:
            if self.loaded_lora[0] == lora_path:
                lora = self.loaded_lora[1]
            else:
                self.loaded_lora = None

        if lora is None:
            lora = comfy.utils.load_torch_file(lora_path, safe_load=True)
            self.loaded_lora = (lora_path, lora)

        model_lora, clip_lora = comfy.sd.load_lora_for_models(model, clip, lora, strength_model, strength_clip)
        return (model_lora, clip_lora)


class Hua_LoraLoaderModelOnly(Hua_LoraLoader):
    @classmethod
    def INPUT_TYPES(s):
        return {"required": { "model": ("MODEL",),
                              "lora_name": (folder_paths.get_filename_list("loras"), ),
                              "strength_model": ("FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}),
                              }}
    RETURN_TYPES = ("MODEL",)
    FUNCTION = "load_lora_model_only"
    CATEGORY = icons.get("hua_boy_one")
    def load_lora_model_only(self, model, lora_name, strength_model):
        return (self.load_lora(model, None, lora_name, strength_model, 0)[0],)


class Hua_LoraLoaderModelOnly2(Hua_LoraLoader):
    @classmethod
    def INPUT_TYPES(s):
        return {"required": { "model": ("MODEL",),
                              "lora_name": (folder_paths.get_filename_list("loras"), ),
                              "strength_model": ("FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}),
                              }}
    RETURN_TYPES = ("MODEL",)
    FUNCTION = "load_lora_model_only"
    CATEGORY = icons.get("hua_boy_one")
    def load_lora_model_only(self, model, lora_name, strength_model):
        return (self.load_lora(model, None, lora_name, strength_model, 0)[0],)


class Hua_LoraLoaderModelOnly3(Hua_LoraLoader):
    @classmethod
    def INPUT_TYPES(s):
        return {"required": { "model": ("MODEL",),
                              "lora_name": (folder_paths.get_filename_list("loras"), ),
                              "strength_model": ("FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}),
                              }}
    RETURN_TYPES = ("MODEL",)
    FUNCTION = "load_lora_model_only"
    CATEGORY = icons.get("hua_boy_one")
    def load_lora_model_only(self, model, lora_name, strength_model):
        return (self.load_lora(model, None, lora_name, strength_model, 0)[0],)


class Hua_LoraLoaderModelOnly4(Hua_LoraLoader):
    @classmethod
    def INPUT_TYPES(s):
        return {"required": { "model": ("MODEL",),
                              "lora_name": (folder_paths.get_filename_list("loras"), ),
                              "strength_model": ("FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}),
                              }}
    RETURN_TYPES = ("MODEL",)
    FUNCTION = "load_lora_model_only"
    CATEGORY = icons.get("hua_boy_one")
    def load_lora_model_only(self, model, lora_name, strength_model):
        return (self.load_lora(model, None, lora_name, strength_model, 0)[0],)


class Hua_CheckpointLoaderSimple:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "ckpt_name": (folder_paths.get_filename_list("checkpoints"), {"tooltip": "The name of the checkpoint (model) to load."}),
            }
        }
    RETURN_TYPES = ("MODEL", "CLIP", "VAE")
    OUTPUT_TOOLTIPS = ("The model used for denoising latents.",
                       "The CLIP model used for encoding text prompts.",
                       "The VAE model used for encoding and decoding images to and from latent space.")
    FUNCTION = "load_checkpoint"

    CATEGORY = icons.get("hua_boy_one")
    DESCRIPTION = "Loads a diffusion model checkpoint, diffusion models are used to denoise latents."

    def load_checkpoint(self, ckpt_name):
        ckpt_path = folder_paths.get_full_path_or_raise("checkpoints", ckpt_name)
        out = comfy.sd.load_checkpoint_guess_config(ckpt_path, output_vae=True, output_clip=True, embedding_directory=folder_paths.get_folder_paths("embeddings"))
        return out[:3]

class Hua_UNETLoader:
    @classmethod
    def INPUT_TYPES(s):
        return {"required": { "unet_name": (folder_paths.get_filename_list("diffusion_models"), ),
                              "weight_dtype": (["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2"],)
                             }}
    RETURN_TYPES = ("MODEL",)
    FUNCTION = "load_unet"

    CATEGORY = icons.get("hua_boy_one")

    def load_unet(self, unet_name, weight_dtype):
        model_options = {}
        if weight_dtype == "fp8_e4m3fn":
            model_options["dtype"] = torch.float8_e4m3fn
        elif weight_dtype == "fp8_e4m3fn_fast":
            model_options["dtype"] = torch.float8_e4m3fn
            model_options["fp8_optimizations"] = True
        elif weight_dtype == "fp8_e5m2":
            model_options["dtype"] = torch.float8_e5m2

        unet_path = folder_paths.get_full_path_or_raise("diffusion_models", unet_name)
        model = comfy.sd.load_diffusion_model(unet_path, model_options=model_options)
        return (model,)
